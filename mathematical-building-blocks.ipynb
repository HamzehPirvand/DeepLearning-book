{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "365e8640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "559a9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f6db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa774e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b0aaab05e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 7777\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdaa26c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c26147dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c150593",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b6a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "286ef355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "print('x_train_shape', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df23b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0e8a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(28, kernel_size=(3, 3), input_shape = input_shape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad87ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fa85102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 29s 14ms/step - loss: 0.2248 - accuracy: 0.9317\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0880 - accuracy: 0.9729\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0619 - accuracy: 0.9810\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0455 - accuracy: 0.9851\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0376 - accuracy: 0.9876\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0300 - accuracy: 0.9899\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0259 - accuracy: 0.99110s - loss: 0.0255 - \n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0228 - accuracy: 0.9917\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0204 - accuracy: 0.9930\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0171 - accuracy: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b0a9a06a00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b11351fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.0638 - accuracy: 0.9847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06381233781576157, 0.9847000241279602]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a22ff884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 5555\n",
    "plt.imshow(x_test[image_index].reshape(28, 28), cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a55f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e932d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "342ea19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d85a8c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1918c8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5914fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92e235e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6de69041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f8b65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e55cac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the image data\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d27f4f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 6s 11ms/step - loss: 0.2543 - accuracy: 0.9261\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1040 - accuracy: 0.9691\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0684 - accuracy: 0.9793\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0498 - accuracy: 0.9851\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0376 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b0a942b310>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44df7544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1800181e-10, 1.0980471e-10, 1.6841612e-06, 1.6709540e-05,\n",
       "       1.2470733e-13, 5.0364157e-09, 8.9357751e-16, 9.9998093e-01,\n",
       "       3.9269928e-08, 6.2550168e-07], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the model to make predictions\n",
    "\n",
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8069d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93f63480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f1561f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0674 - accuracy: 0.9805\n",
      "test_acc: 0.9804999828338623\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model on new data\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'test_acc: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1e25959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data representations for neural networks\n",
    "#Scalars (rank-0 tensors)\n",
    "\n",
    "import numpy as np\n",
    "x = np.array(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a20e4be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "016ffc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectors (rank-1 tensors)\n",
    "\n",
    "x = np.array([12, 3, 6, 14, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3e75047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14,  7])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fc4176b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2067a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matrices (rank-2 tensors)\n",
    "\n",
    "\n",
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c518d1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 78,  2, 34,  0],\n",
       "       [ 6, 79,  3, 35,  1],\n",
       "       [ 7, 80,  4, 36,  2]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d38a8082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "033a7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rank-3 and higher-rank tensors\n",
    "\n",
    "\n",
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],x.\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "402ecd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 5, 78,  2, 34,  0],\n",
       "        [ 6, 79,  3, 35,  1],\n",
       "        [ 7, 80,  4, 36,  2]],\n",
       "\n",
       "       [[ 5, 78,  2, 34,  0],\n",
       "        [ 6, 79,  3, 35,  1],\n",
       "        [ 7, 80,  4, 36,  2]],\n",
       "\n",
       "       [[ 5, 78,  2, 34,  0],\n",
       "        [ 6, 79,  3, 35,  1],\n",
       "        [ 7, 80,  4, 36,  2]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a265cba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3bcbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key attributes\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebc1bc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f495cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "769fe4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0fc3be98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displaying the fourth digit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5822a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b50b06a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manipulating tensors in NumPy\n",
    "\n",
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7633b138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9ec9e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31d9f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The notion of data batches\n",
    "\n",
    "batch = train_images[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cab7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf5c7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7fb1b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Element-wise operations\n",
    "\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0a91fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "56c77c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.01 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "    \n",
    "print('Took: {0:.2f} s'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4436aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "\n",
    "print('Took: {0:.2f} s'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8659e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Broadcasting\n",
    "\n",
    "import numpy as np\n",
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b26b9025",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.expand_dims(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea40b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.concatenate([y] * 32, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "abbf015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "66f5efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8fba5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor product\n",
    "\n",
    "x = np.random.random((32,))\n",
    "y = np.random.random((32,))\n",
    "z = np.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f77876d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c56d2def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "            \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9de822e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce83024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "            \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e980631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor reshaping\n",
    "\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "714c97f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "             [2., 3.],\n",
    "             [4., 5.]])\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6169a719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6fbda2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "87ce92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The gradient tape in TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "x = tf.Variable(0.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "04019cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(tf.random.uniform((2, 2)))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "162d6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.uniform((2, 2)))\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2, 2))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df3a2a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A simple Dense class\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "        \n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval = 1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "        \n",
    "        \n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3974d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A simple Sequential class\n",
    "\n",
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7b39191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size = 512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "58fb8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A batch generator\n",
    "\n",
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "        \n",
    "        \n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5d68806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running one training step\n",
    "\n",
    "def one_training_step(models, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(labels_batch, predictions)\n",
    "        \n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "63f59542",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0cea4d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    optimizer.apply_gradients(zip(gradients, weights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
